{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: [code](https://zhuanlan.zhihu.com/p/356609372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Activation, Dense, Input, Conv2D, Flatten, Reshape, Conv2DTranspose, LeakyReLU, BatchNormalization, concatenate\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "num_labels = np.amax(y_train) + 1\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "model_name = \"cgan_mnist\"\n",
    "# network parameters\n",
    "# the latent or z vector is 100-dim\n",
    "latent_size = 100\n",
    "batch_size = 64\n",
    "train_steps = 10000\n",
    "lr = 2e-4\n",
    "decay = 6e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(inputs, labels, image_size):\n",
    "    image_resize = image_size // 4\n",
    "    layer_filters = [128, 64, 32, 1] # network parameters\n",
    "\n",
    "    x = concatenate([inputs, labels], axis=1)\n",
    "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
    "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        strides = 2 if filters > layer_filters[-2] else 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(kernel_size=5, filters=filters, strides=strides, padding='same')(x)\n",
    "\n",
    "    x = Activation('sigmoid')(x)\n",
    "    generator = Model([inputs, labels], x, name='generator')\n",
    "    print(generator.summary())\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(inputs, labels, image_size):\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    y = Dense(image_size * image_size)(labels)\n",
    "    y = Reshape((image_size, image_size, 1))(y)\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        strides = 1 if filters == layer_filters[-1] else 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(kernel_size=5, filters=filters, strides=strides, padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    # input is conditioned by labels\n",
    "    discriminator = Model([inputs, labels], x, name='discriminator')\n",
    "    print(discriminator.summary())\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, data, params):\n",
    "    # the GAN models\n",
    "    generator, discriminator, adversarial = models\n",
    "    # images and labels\n",
    "    x_train, y_train = data\n",
    "    # network parameters\n",
    "    batch_size, latent_size, train_steps, num_labels, model_name = params\n",
    "    # the generator image is saved every 500 steps\n",
    "    save_interval = 500\n",
    "    # noise vector to see how the generator output evolves during training\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "    # one-hot label the noise will be conditioned to\n",
    "    noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\n",
    "    # number of elements in train dataset\n",
    "    train_size = x_train.shape[0]\n",
    "\n",
    "    print(f\"{model_name} Labels for generated images: {np.argmax(noise_class, axis=1)}\")\n",
    "\n",
    "    for i in range(train_steps):\n",
    "        # train the discriminator for 1 batch\n",
    "        # 1 batch of real (label=1.0) and fake images (label=0.0)\n",
    "        # randomly pick real images from dataset\n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "        # corresponding one-hot labels of real images\n",
    "        real_labels = y_train[rand_indexes]\n",
    "        # generate fake images from noise using generator\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # assign random one-hot labels\n",
    "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
    "                                                          batch_size)]\n",
    "\n",
    "        # generate fake images conditioned on fake labels\n",
    "        fake_images = generator.predict([noise, fake_labels])\n",
    "        # real + fake images = 1 batch of train data\n",
    "        x = np.concatenate((real_images, fake_images))\n",
    "        # real + fake one-hot labels = 1 batch of train one-hot labels\n",
    "        labels = np.concatenate((real_labels, fake_labels))\n",
    "\n",
    "        # label real and fake images\n",
    "        # real images label is 1.0\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        # fake images label is 0.0\n",
    "        y[batch_size:, :] = 0.0\n",
    "        # train discriminator network, log the loss and accuracy\n",
    "        loss, acc = discriminator.train_on_batch([x, labels], y)\n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "        # train the adversarial network for 1 batch\n",
    "        # 1 batch of fake images conditioned on fake 1-hot labels\n",
    "        # w/ label=1.0\n",
    "        # since the discriminator weights are frozen in\n",
    "        # adversarial network only the generator is trained\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # assign random one-hot labels\n",
    "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
    "                                                          batch_size)]\n",
    "        # label fake images as real or 1.0\n",
    "        y = np.ones([batch_size, 1])\n",
    "        # train the adversarial network\n",
    "        # note that unlike in discriminator training,\n",
    "        # we do not save the fake images in a variable\n",
    "        # the fake images go to the discriminator input\n",
    "        # of the adversarial for classification\n",
    "        # log the loss and accuracy\n",
    "        loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\n",
    "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "        print(log)\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            # plot generator images on a periodic basis\n",
    "            plot_images(generator,\n",
    "                        noise_input=noise_input,\n",
    "                        noise_class=noise_class,\n",
    "                        show=False,\n",
    "                        step=(i + 1),\n",
    "                        model_name=model_name)\n",
    "            generator.save(f\"{model_name}/G_{i+1:05d}.h5\")\n",
    "\n",
    "    # save the model after training the generator\n",
    "    # the trained generator can be reloaded for\n",
    "    # future MNIST digit generation\n",
    "    generator.save(f\"{model_name}/G_{i+1:05d}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models():\n",
    "    input_shape = (image_size, image_size, 1)\n",
    "    label_shape = (num_labels, )\n",
    "\n",
    "    # build discriminator model\n",
    "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "    labels = Input(shape=label_shape, name='class_labels')\n",
    "\n",
    "    discriminator = build_discriminator(inputs, labels, image_size)\n",
    "    # [1] or original paper uses Adam,\n",
    "    # but discriminator converges easily with RMSprop\n",
    "    optimizer = RMSprop(lr=lr, decay=decay)\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "    plot_model(discriminator, to_file='advenced_discriminator.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # build generator model\n",
    "    input_shape = (latent_size, )\n",
    "    inputs = Input(shape=input_shape, name='z_input')\n",
    "    generator = build_generator(inputs, labels, image_size)\n",
    "    plot_model(generator, to_file='advenced_generator.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "    # build adversarial model = generator + discriminator\n",
    "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
    "    # freeze the weights of discriminator during adversarial training\n",
    "    discriminator.trainable = False\n",
    "    outputs = discriminator([generator([inputs, labels]), labels])\n",
    "    adversarial = Model([inputs, labels],\n",
    "                        outputs,\n",
    "                        name=model_name)\n",
    "    adversarial.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'])\n",
    "    print(adversarial.summary())\n",
    "\n",
    "    # train discriminator and adversarial networks\n",
    "    models = (generator, discriminator, adversarial)\n",
    "    data = (x_train, y_train)\n",
    "    params = (batch_size, latent_size, train_steps, num_labels, model_name)\n",
    "    train(models, data, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator, noise_input, noise_class, show=False, step=0, model_name=\"gan\"):\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict([noise_input, noise_class])\n",
    "    print(model_name, \" labels for generated images: \",\n",
    "          np.argmax(noise_class, axis=1))\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(generator, class_label=None):\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "    step = 0\n",
    "    if class_label is None:\n",
    "        num_labels = 10\n",
    "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
    "    else:\n",
    "        noise_class = np.zeros((16, 10))\n",
    "        noise_class[:, class_label] = 1\n",
    "        step = class_label\n",
    "\n",
    "    plot_images(generator,\n",
    "                noise_input=noise_input,\n",
    "                noise_class=noise_class,\n",
    "                show=True,\n",
    "                step=step,\n",
    "                model_name=\"test_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "fit_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load generator model\n",
    "generator = load_model(\"cgan_mnist/G_10000.h5\")\n",
    "generator.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a specific digit to generate\n",
    "digit_label = 0\n",
    "test_generator(generator, digit_label)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9c8b6b82104be7723b6ce605638c87ba5946fa3b8761a51c3206ec9ef421040"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfgpu-2.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
